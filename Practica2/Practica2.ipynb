{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0ee14f",
   "metadata": {},
   "source": [
    "# Pràctica 2\n",
    "\n",
    "L'objectiu d'aquesta segona pràctica es demostrar que heu assolit els conceptes que s'han explicar a l'assignatura i s'han practicat a les sessions presencials, relacionats amb el disseny i l'ús de xarxes neurals. \n",
    "\n",
    "Aquesta pràctica consta de 3 enunciats dels quals només heu de realitzar el que us hagi tocat per sorteig.\n",
    "\n",
    "**Condicions**\n",
    "1. El model que solucioni el problema estarà basat en xarxes neurals, aquestes s'han d'entrenar i avaluar emprant la llibreria _Pytorch_.\n",
    "2. Es demana que com a mínim s'avaluin 2 models diferents: un que ha d'estar creat per vosaltres i un altre que es basi en una xarxa ja existent. Evidentment es permeten modificacions de la ja existen per adaptar-ho al problema que es vol resoldre.\n",
    "3. El resultat del treball serà un informe on s'expliqui el procés que s'ha dut a terme per arribar a la que considereu que és millor solució. El document serà en format `pdf`. Podreu adjuntar una carpeta amb el codi i recursos que trobeu necessaris per comprovar la veracitat del que explicau al document.\n",
    "4. Aquest document ha de tenir un llenguatge formal i tècnic i ha d'estar correctament estructurat:\n",
    "    - Introducció al problema\n",
    "    - Solucions considerades (dades, característiques, models, mètriques)\n",
    "    - Experiments realitzats\n",
    "    - Resultats dels experiments\n",
    "    - Conclusions\n",
    "5. A més del document explicatiu s'ha d'adjuntar un fitxer amb els pesos del millor entrenament de cada una de les xarxes que heu emprat (la que heu dissenyat vosaltres i la que ja existia), de tal manera que el professor pugui validar els resultats sense haver de repetir l'entrenament. Sense l'adjunció d'aquests fitxers la pràctica no es podrà aprovar.\n",
    "6. Les dades depenen de cada un dels tres enunciats i les trobareu en el seu apartat.\n",
    "\n",
    "\n",
    "**Avaluació**\n",
    "\n",
    "- El treball es durà a terme en parelles.\n",
    "- El professor es reserva la possibilitat de convocar als grups a una revisió de la pràctica de forma presencial.\n",
    "- Només està permés emprar tècniques de disseny i entrenament vistes a classe.\n",
    "- Tot el que no està fet pels alumnes ha d'estar referenciat, en cas contrari es considerarà com una còpia.\n",
    "\n",
    "\n",
    "**Data d'entrega**\n",
    "\n",
    "- Aquest treball s'entrega dia 15 de gener.\n",
    "- Es realitzarà una tutoria dilluns 9 de gener a les 15:30.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47b046",
   "metadata": {},
   "source": [
    "## Enunciat 1: Classificació\n",
    "\n",
    "El problema que heu de resoldre en aquest cas és un problema de classificació amb el conjunt de dades _Horses or Human_ dataset [enllaç](https://laurencemoroney.com/datasets.html). És un conjunt de dades generat per ordinador en el que trobareu dues classes diferents: persones i cavalls (500 imatges de cavalls i 547 imatges de persones). També dos subconjunts de dades ja definits: entrenament  i validació. Les imatges tenen una mida de 300x300 pixels i es troben en RGB.\n",
    "\n",
    "A més de la feina de classificació i presentació dels resultats amb el conjunt de dades que es proporciona, també es demana que construiu un petit conjunt d'imatges (entre 10 i 20) de persones i cavalls reals com a conjunt de test i obtingueu les mesures rendiment adients per aquestes dades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388d6f4",
   "metadata": {},
   "source": [
    "**Exemples del dataset**\n",
    "<div style=\"display:flex\">\n",
    "     <div style=\"flex:1;padding-right:10px;\">\n",
    "          <img src=\"img/human01-16.png\" width=\"200\"/>\n",
    "     </div>\n",
    "     <div style=\"flex:1;padding-left:10px;\">\n",
    "          <img src=\"img/horse03-3.png\" width=\"200\"/>\n",
    "     </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanHorseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "       \n",
    "    #  def load_data(self):\n",
    "    #     for file in os.listdir(self.path):\n",
    "    #         if file.endswith(\".png\"):\n",
    "    #             image = Image.open(os.path.join(self.path, file))\n",
    "    #             if self.transform is not None:\n",
    "    #                 image = self.transform(image)\n",
    "    #             self.data.append(image)\n",
    "    #             self.labels.append(0 if file.startswith(\"horse\") else 1)\n",
    "   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.path,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, imgs_path):\n",
    "        self.imgs_path = imgs_path\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        print(file_list)\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.png\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        print(self.data)\n",
    "        self.class_map = {\"horses\" : 0, \"humans\": 1}\n",
    "        self.img_dim = (300, 300)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        return img_tensor, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f916a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 100\n",
    "\n",
    "dataset = CustomDataset(\"data/train/\")\n",
    "data_loader = DataLoader(dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "# Creamos los datasets de entrenamiento y test, estan dentro de data/train\n",
    "# y data/test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
