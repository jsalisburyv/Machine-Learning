{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf12ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de74b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "693375ea",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e4de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.files_paths = [f for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.data = [Image.open(os.path.join(self.path, f)).convert('RGB') for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.labels = [f.split('-')[0] for f in self.files_paths]\n",
    "        self.labels = [0 if x == 'horse' else 1 for x in self.labels]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # image = transforms.ToTensor()(image)\n",
    "        # image = image.permute(1, 2, 0)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5efd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_normalization_values(path):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation of the pixel values for each channel\n",
    "    in the images stored in the specified folder.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.png'):\n",
    "            image = Image.open(os.path.join(path, file))\n",
    "            image_np = np.array(image)\n",
    "\n",
    "            red, green, blue = image_np[:,:,0], image_np[:,:,1], image_np[:,:,2]\n",
    "\n",
    "            red_values.append(red)\n",
    "            green_values.append(green)\n",
    "            blue_values.append(blue)\n",
    "\n",
    "    red_mean = np.mean(red_values)/255\n",
    "    green_mean = np.mean(green_values)/255\n",
    "    blue_mean = np.mean(blue_values)/255\n",
    "\n",
    "    red_std = np.std(red_values)/255\n",
    "    green_std = np.std(green_values)/255\n",
    "    blue_std = np.std(blue_values)/255\n",
    "\n",
    "    return (red_mean, green_mean, blue_mean), (red_std, green_std, blue_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39054741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std = get_normalization_values(\"data/train/\")\n",
    "\n",
    "# mean = torch.tensor(mean)\n",
    "# std = torch.tensor(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f916a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train = CustomDataset(path = \"data/train/\",  transform=transform)\n",
    "test = CustomDataset(path = \"data/validation/\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=train_batch_size, shuffle=True, pin_memory = True)\n",
    "test_loader = DataLoader(test, batch_size=test_batch_size, shuffle=True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8938e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first batch of data from the data loader\n",
    "# batch = next(iter(train_loader))\n",
    "# data, labels = batch\n",
    "\n",
    "# # Make a figure with subplots\n",
    "# fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "\n",
    "# # Iterate over the data and labels and plot the images\n",
    "# for i, (data, label) in enumerate(zip(data, labels)):\n",
    "#     # Calculate the row and column indices for the subplot\n",
    "#     data = np.squeeze(data)\n",
    "\n",
    "#     row = i // 8\n",
    "#     col = i % 8\n",
    "#     # Plot the image on the corresponding subplot\n",
    "#     ax = axs[row, col]\n",
    "#     ax.imshow(data)\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da49e5e9",
   "metadata": {},
   "source": [
    "# Model Nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9069a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd12761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_CNN(nn.Module):\n",
    "    def __init__(self, channels, feature_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 3, 2, 1),\n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1),\n",
    "            self.block(feature_size*2, feature_size*4, 3, 2, 1),\n",
    "            self.block(feature_size*4, feature_size*8, 3, 2, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33079dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_FCN(nn.Module):\n",
    "    def __init__(self, channels, feature_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 3, 2, 1), # 300x300 --> 150x150\n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1), # 150x150 --> 75x75\n",
    "            self.block(feature_size*2, feature_size*4, 3, 2, 1), # 75x75 --> 38x38\n",
    "            self.block(feature_size*4, feature_size*8, 3, 2, 1), # 38x38 --> 19x19\n",
    "            self.block(feature_size*8, feature_size*4, 3, 2, 1), # 19x19 --> 10x10\n",
    "            self.block(feature_size*4, feature_size*2, 3, 2, 1), # 10x10 --> 5x5\n",
    "            self.block(feature_size*2, feature_size, 3, 2, 1), # 5x5 --> 3x3\n",
    "            self.block(feature_size, 1, 3, 2, 0), # 3x3 --> 2x2\n",
    "            nn.Flatten(),\n",
    "            nn.Softmax(dim=1)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c84fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_CNN = 0.001\n",
    "lr_FCN = 0.01\n",
    "\n",
    "channels = 3\n",
    "\n",
    "feature_size_CNN = 2\n",
    "feature_size_FCN = 2\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "num_epochs_CNN = 50\n",
    "num_epochs_FCN = 50\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        net_CNN = Net_CNN(channels, feature_size_CNN, num_classes).to(device)\n",
    "\n",
    "net_FCN = Net_FCN(channels, feature_size_FCN).to(device)\n",
    "\n",
    "net_CNN.apply(weights_init)\n",
    "net_FCN.apply(weights_init)\n",
    "\n",
    "criterion_CNN = nn.CrossEntropyLoss().to(device)\n",
    "criterion_FCN = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer_CNN = torch.optim.SGD(net_CNN.parameters(), lr=lr_CNN, momentum=0.9).to(device)\n",
    "optimizer_FCN = torch.optim.SGD(net_FCN.parameters(), lr=lr_FCN, momentum=0.9).to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adde7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            model_inference        39.90%       2.421ms        99.47%       6.035ms       6.035ms     420.000us        11.04%       3.792ms       3.792ms             1  \n",
      "                                   aten::to         2.32%     141.000us        55.74%       3.382ms      93.944us     146.000us         3.84%       2.944ms      81.778us            36  \n",
      "                             aten::_to_copy         4.43%     269.000us        53.42%       3.241ms     101.281us     219.000us         5.76%       2.798ms      87.438us            32  \n",
      "                                aten::copy_        47.63%       2.890ms        47.63%       2.890ms      90.312us       2.515ms        66.11%       2.515ms      78.594us            32  \n",
      "                               aten::detach         1.04%      63.000us         1.40%      85.000us       4.250us      80.000us         2.10%     120.000us       6.000us            20  \n",
      "                        aten::empty_strided         1.35%      82.000us         1.35%      82.000us       2.562us      64.000us         1.68%      64.000us       2.000us            32  \n",
      "                                aten::zeros         0.86%      52.000us         1.01%      61.000us      12.200us      32.000us         0.84%      52.000us      10.400us             5  \n",
      "                                 aten::ones         0.58%      35.000us         0.71%      43.000us      10.750us      26.000us         0.68%      42.000us      10.500us             4  \n",
      "                             aten::uniform_         0.58%      35.000us         0.58%      35.000us       2.917us      24.000us         0.63%      24.000us       2.000us            12  \n",
      "                                aten::empty         0.49%      30.000us         0.49%      30.000us       0.882us      68.000us         1.79%      68.000us       2.000us            34  \n",
      "                                     detach         0.36%      22.000us         0.36%      22.000us       1.100us      40.000us         1.05%      40.000us       2.000us            20  \n",
      "                                aten::fill_         0.20%      12.000us         0.20%      12.000us       1.000us      24.000us         0.63%      24.000us       2.000us            12  \n",
      "                              aten::detach_         0.20%      12.000us         0.20%      12.000us       3.000us      16.000us         0.42%      24.000us       6.000us             4  \n",
      "                                aten::zero_         0.05%       3.000us         0.05%       3.000us       0.176us      34.000us         0.89%      34.000us       2.000us            17  \n",
      "                           aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         0.21%       8.000us       2.000us             4  \n",
      "                                    detach_         0.00%       0.000us         0.00%       0.000us       0.000us       8.000us         0.21%       8.000us       2.000us             4  \n",
      "    aten::_has_compatible_shallow_copy_type         0.00%       0.000us         0.00%       0.000us       0.000us      80.000us         2.10%      80.000us       2.000us            40  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 6.067ms\n",
      "Self CUDA time total: 3.804ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41aa5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_FCN(\n",
      "  (main): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(2, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(4, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "Total number of parameters CNN:  1810\n",
      "Total number of parameters FCN:  3186\n"
     ]
    }
   ],
   "source": [
    "print(net_FCN)\n",
    "pytorch_total_params_CNN = sum(p.numel() for p in net_CNN.parameters())\n",
    "pytorch_total_params_FCN = sum(p.numel() for p in net_FCN.parameters())\n",
    "print(\"Total number of parameters CNN: \", pytorch_total_params_CNN)\n",
    "print(\"Total number of parameters FCN: \", pytorch_total_params_FCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101cbf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonny\\AppData\\Local\\Temp\\ipykernel_308\\229094773.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n",
      "C:\\Users\\jonny\\AppData\\Local\\Temp\\ipykernel_308\\229094773.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.7076, Test Loss: 0.6944, Train Acc: 0.4994, Test Acc: 0.5000\n",
      "Epoch 2/50, Train Loss: 0.6734, Test Loss: 0.6937, Train Acc: 0.5594, Test Acc: 0.5000\n",
      "Epoch 3/50, Train Loss: 0.6692, Test Loss: 0.6925, Train Acc: 0.5573, Test Acc: 0.5000\n",
      "Epoch 4/50, Train Loss: 0.6445, Test Loss: 0.6874, Train Acc: 0.6060, Test Acc: 0.5938\n",
      "Epoch 5/50, Train Loss: 0.6696, Test Loss: 0.6304, Train Acc: 0.5726, Test Acc: 0.5625\n",
      "Epoch 6/50, Train Loss: 0.6216, Test Loss: 0.6169, Train Acc: 0.6811, Test Acc: 0.6641\n",
      "Epoch 7/50, Train Loss: 0.6071, Test Loss: 0.5948, Train Acc: 0.6673, Test Acc: 0.6953\n",
      "Epoch 8/50, Train Loss: 0.5778, Test Loss: 0.5504, Train Acc: 0.7414, Test Acc: 0.8320\n",
      "Epoch 9/50, Train Loss: 0.5676, Test Loss: 0.5510, Train Acc: 0.7325, Test Acc: 0.8516\n",
      "Epoch 10/50, Train Loss: 0.5441, Test Loss: 0.5327, Train Acc: 0.7858, Test Acc: 0.8242\n",
      "Epoch 11/50, Train Loss: 0.5443, Test Loss: 0.5234, Train Acc: 0.8024, Test Acc: 0.8828\n",
      "Epoch 12/50, Train Loss: 0.5325, Test Loss: 0.5106, Train Acc: 0.8064, Test Acc: 0.8867\n",
      "Epoch 13/50, Train Loss: 0.5306, Test Loss: 0.5187, Train Acc: 0.8058, Test Acc: 0.8203\n",
      "Epoch 14/50, Train Loss: 0.4967, Test Loss: 0.4918, Train Acc: 0.8603, Test Acc: 0.8633\n",
      "Epoch 15/50, Train Loss: 0.4992, Test Loss: 0.4969, Train Acc: 0.8713, Test Acc: 0.8398\n",
      "Epoch 16/50, Train Loss: 0.5000, Test Loss: 0.4869, Train Acc: 0.8787, Test Acc: 0.8867\n",
      "Epoch 17/50, Train Loss: 0.4929, Test Loss: 0.4928, Train Acc: 0.8722, Test Acc: 0.8750\n",
      "Epoch 18/50, Train Loss: 0.4921, Test Loss: 0.4926, Train Acc: 0.8805, Test Acc: 0.8398\n",
      "Epoch 19/50, Train Loss: 0.4835, Test Loss: 0.4837, Train Acc: 0.8866, Test Acc: 0.8789\n",
      "Epoch 20/50, Train Loss: 0.4798, Test Loss: 0.4875, Train Acc: 0.9017, Test Acc: 0.8477\n",
      "Epoch 21/50, Train Loss: 0.4925, Test Loss: 0.4716, Train Acc: 0.8922, Test Acc: 0.8906\n",
      "Epoch 22/50, Train Loss: 0.4706, Test Loss: 0.4569, Train Acc: 0.8931, Test Acc: 0.8789\n",
      "Epoch 23/50, Train Loss: 0.4729, Test Loss: 0.4724, Train Acc: 0.9200, Test Acc: 0.8633\n",
      "Epoch 24/50, Train Loss: 0.4841, Test Loss: 0.4631, Train Acc: 0.8771, Test Acc: 0.8828\n",
      "Epoch 25/50, Train Loss: 0.4474, Test Loss: 0.4588, Train Acc: 0.9366, Test Acc: 0.8906\n",
      "Epoch 26/50, Train Loss: 0.4480, Test Loss: 0.4579, Train Acc: 0.9430, Test Acc: 0.8867\n",
      "Epoch 27/50, Train Loss: 0.4610, Test Loss: 0.4530, Train Acc: 0.9262, Test Acc: 0.8789\n",
      "Epoch 28/50, Train Loss: 0.4531, Test Loss: 0.4608, Train Acc: 0.9280, Test Acc: 0.8672\n",
      "Epoch 29/50, Train Loss: 0.4620, Test Loss: 0.4513, Train Acc: 0.9029, Test Acc: 0.8750\n",
      "Epoch 30/50, Train Loss: 0.4355, Test Loss: 0.4454, Train Acc: 0.9513, Test Acc: 0.9062\n",
      "Epoch 31/50, Train Loss: 0.4495, Test Loss: 0.4608, Train Acc: 0.9390, Test Acc: 0.8750\n",
      "Epoch 32/50, Train Loss: 0.4500, Test Loss: 0.4643, Train Acc: 0.9338, Test Acc: 0.8828\n",
      "Epoch 33/50, Train Loss: 0.4364, Test Loss: 0.4389, Train Acc: 0.9513, Test Acc: 0.8867\n",
      "Epoch 34/50, Train Loss: 0.4394, Test Loss: 0.4464, Train Acc: 0.9504, Test Acc: 0.8789\n",
      "Epoch 35/50, Train Loss: 0.4233, Test Loss: 0.4535, Train Acc: 0.9651, Test Acc: 0.8750\n",
      "Epoch 36/50, Train Loss: 0.4261, Test Loss: 0.4437, Train Acc: 0.9623, Test Acc: 0.8867\n",
      "Epoch 37/50, Train Loss: 0.4377, Test Loss: 0.4908, Train Acc: 0.9550, Test Acc: 0.8125\n",
      "Epoch 38/50, Train Loss: 0.4239, Test Loss: 0.4707, Train Acc: 0.9697, Test Acc: 0.8477\n",
      "Epoch 39/50, Train Loss: 0.4122, Test Loss: 0.4468, Train Acc: 0.9752, Test Acc: 0.8711\n",
      "Epoch 40/50, Train Loss: 0.4114, Test Loss: 0.4533, Train Acc: 0.9798, Test Acc: 0.8594\n",
      "Epoch 41/50, Train Loss: 0.4195, Test Loss: 0.4496, Train Acc: 0.9798, Test Acc: 0.8672\n",
      "Epoch 42/50, Train Loss: 0.4234, Test Loss: 0.4510, Train Acc: 0.9623, Test Acc: 0.8633\n",
      "Epoch 43/50, Train Loss: 0.4182, Test Loss: 0.4499, Train Acc: 0.9724, Test Acc: 0.8828\n",
      "Epoch 44/50, Train Loss: 0.4122, Test Loss: 0.4651, Train Acc: 0.9651, Test Acc: 0.8633\n",
      "Epoch 45/50, Train Loss: 0.4227, Test Loss: 0.4843, Train Acc: 0.9743, Test Acc: 0.8242\n",
      "Epoch 46/50, Train Loss: 0.4665, Test Loss: 0.6007, Train Acc: 0.9081, Test Acc: 0.6836\n",
      "Epoch 47/50, Train Loss: 0.4297, Test Loss: 0.4636, Train Acc: 0.9412, Test Acc: 0.8516\n",
      "Epoch 48/50, Train Loss: 0.4145, Test Loss: 0.4411, Train Acc: 0.9586, Test Acc: 0.8789\n",
      "Epoch 49/50, Train Loss: 0.4231, Test Loss: 0.4308, Train Acc: 0.9510, Test Acc: 0.8984\n",
      "Epoch 50/50, Train Loss: 0.4033, Test Loss: 0.4339, Train Acc: 0.9789, Test Acc: 0.8984\n",
      "100.90352773666382\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "writer_train = SummaryWriter(f\"logs/train\")\n",
    "writer_test = SummaryWriter(f\"logs/test\")\n",
    "\n",
    "step_train = 0\n",
    "step_test = 0\n",
    "\n",
    "tr_loss = np.zeros((num_epochs_CNN))\n",
    "te_loss = np.zeros((num_epochs_CNN))\n",
    "\n",
    "tr_acc = np.zeros((num_epochs_CNN))\n",
    "te_acc = np.zeros((num_epochs_CNN))\n",
    "\n",
    "for epoch in range(num_epochs_CNN):\n",
    "\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    net_CNN.train()\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_CNN.zero_grad(set_to_none=True)\n",
    "        outputs = net_CNN(data)\n",
    "        loss = criterion_CNN(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_CNN.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # compute the accuracy for this batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / len(labels)\n",
    "        train_acc += accuracy\n",
    "\n",
    "\n",
    "        writer_train.add_scalar(\"Training loss\", loss, global_step=step_train)\n",
    "        step_train += 1\n",
    "    \n",
    "    net_CNN.eval()\n",
    "    with torch.no_grad():\n",
    "        for j, (data, labels) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            labels = torch.tensor(labels)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net_CNN(data)\n",
    "            loss = criterion_CNN(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # compute the accuracy for this batch\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = correct / len(labels)\n",
    "            test_acc += accuracy\n",
    "\n",
    "            writer_test.add_scalar(\"Test loss\", loss, global_step=step_test)\n",
    "            step_test += 1\n",
    "\n",
    "    # compute the average loss and accuracy for each epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "\n",
    "    tr_loss[epoch] = train_loss\n",
    "    te_loss[epoch] = test_loss\n",
    "    tr_acc[epoch] = train_acc\n",
    "    te_acc[epoch] = test_acc\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_CNN}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(tr_acc, label='Train accuracy')\n",
    "plt.plot(te_acc, label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f00367ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\AppData\\Local\\Temp\\ipykernel_16500\\914054602.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data, labels = data.to(device), torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\AppData\\Local\\Temp\\ipykernel_16500\\914054602.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data, labels = data.to(device), torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 49.6936, Test Loss: 50.0000, Train Acc: 29.4118, Test Acc: 32.0000\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>) tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     16\u001b[0m net_FCN\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     18\u001b[0m     data, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mtensor(labels)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m     optimizer_FCN\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [3], line 20\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     17\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 20\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# image = transforms.ToTensor()(image)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# image = image.permute(1, 2, 0)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\TFG\\lib\\site-packages\\torchvision\\transforms\\functional.py:171\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    169\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step_test = 0\n",
    "\n",
    "tr_loss = np.zeros((num_epochs_FCN))\n",
    "te_loss = np.zeros((num_epochs_FCN))\n",
    "\n",
    "tr_acc = np.zeros((num_epochs_FCN))\n",
    "te_acc = np.zeros((num_epochs_FCN))\n",
    "\n",
    "for epoch in range(num_epochs_FCN):\n",
    "\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    net_FCN.train()\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "        optimizer_FCN.zero_grad(set_to_none=True)\n",
    "        outputs = net_FCN(data)\n",
    "    \n",
    "        labels = labels.unsqueeze(1)\n",
    "        print(outputs, labels)\n",
    "\n",
    "        loss = F.binary_cross_entropy(outputs,  labels.type(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer_FCN.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # compute the accuracy for this batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / len(labels)\n",
    "        train_acc += accuracy\n",
    "\n",
    "    net_FCN.eval()\n",
    "    with torch.no_grad():\n",
    "        for j, (data, labels) in enumerate(test_loader):\n",
    "            data, labels = data.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "            optimizer_FCN.zero_grad(set_to_none=True)\n",
    "            outputs = net_FCN(data)\n",
    "        \n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = F.binary_cross_entropy(outputs,  labels.type(torch.float32))\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # compute the accuracy for this batch\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = correct / len(labels)\n",
    "            test_acc += accuracy\n",
    "\n",
    "    # compute the average loss and accuracy for each epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "\n",
    "    tr_loss[epoch] = train_loss\n",
    "    te_loss[epoch] = test_loss\n",
    "    tr_acc[epoch] = train_acc\n",
    "    te_acc[epoch] = test_acc\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_FCN}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(tr_acc, label='Train accuracy')\n",
    "plt.plot(te_acc, label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ef6fe11",
   "metadata": {},
   "source": [
    "# Model Existent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f706533f",
   "metadata": {},
   "source": [
    "https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "855d20d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.1\n",
      "Torchvision Version:  0.14.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78d569e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77eeb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d24341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ca0bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(num_classes, feature_extract, weights=None):\n",
    "    model = resnet50(weights=weights)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    input_size = 224\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbc67c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, input_size = init_model(num_classes, feature_extract)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "02fa8fd54c95af2be9661fa379357b4da443ac0bd23893c8dcfed0cde6713a10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
