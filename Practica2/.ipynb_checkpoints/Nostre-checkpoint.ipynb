{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12ff59",
   "metadata": {
    "id": "bf12ff59"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74b30a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1673121331801,
     "user": {
      "displayName": "julian wallis",
      "userId": "17524896017552644151"
     },
     "user_tz": -60
    },
    "id": "de74b30a",
    "outputId": "9cf4d863-ae59-4653-acbb-4013643de6bf"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693375ea",
   "metadata": {
    "id": "693375ea"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4de12",
   "metadata": {
    "id": "f0e4de12"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.files_paths = [f for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.data = [Image.open(os.path.join(self.path, f)).convert('RGB') for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.labels = [f.split('-')[0] for f in self.files_paths]\n",
    "        self.labels = [0 if x == 'humans' else 1 for x in self.labels]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5efd00",
   "metadata": {
    "id": "de5efd00"
   },
   "outputs": [],
   "source": [
    "def get_normalization_values(path):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation of the pixel values for each channel\n",
    "    in the images stored in the specified folder.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.png'):\n",
    "            image = Image.open(os.path.join(path, file))\n",
    "            image_np = np.array(image)\n",
    "\n",
    "            red, green, blue = image_np[:,:,0], image_np[:,:,1], image_np[:,:,2]\n",
    "\n",
    "            red_values.append(red)\n",
    "            green_values.append(green)\n",
    "            blue_values.append(blue)\n",
    "\n",
    "    red_mean = np.mean(red_values)/255\n",
    "    green_mean = np.mean(green_values)/255\n",
    "    blue_mean = np.mean(blue_values)/255\n",
    "\n",
    "    red_std = np.std(red_values)/255\n",
    "    green_std = np.std(green_values)/255\n",
    "    blue_std = np.std(blue_values)/255\n",
    "\n",
    "    return (red_mean, green_mean, blue_mean), (red_std, green_std, blue_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39054741",
   "metadata": {
    "id": "39054741"
   },
   "outputs": [],
   "source": [
    "mean, std = get_normalization_values(\"data/train/\")\n",
    "\n",
    "mean = torch.tensor(mean)\n",
    "std = torch.tensor(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f916a7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36832,
     "status": "ok",
     "timestamp": 1673121534926,
     "user": {
      "displayName": "julian wallis",
      "userId": "17524896017552644151"
     },
     "user_tz": -60
    },
    "id": "4f916a7a",
    "outputId": "560ba64d-ba21-46e2-97db-0badb95e6ce8"
   },
   "outputs": [],
   "source": [
    "print(mean, std)\n",
    "train_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "channels = 3\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train = CustomDataset(path = \"data/train/\",  transform=transform)\n",
    "test = CustomDataset(path = \"data/validation/\", transform=transform)\n",
    "\n",
    "# train = datasets.ImageFolder(\"data2/train\", transform)\n",
    "# test = datasets.ImageFolder(\"data2/test\", transform)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test, batch_size=test_batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49e5e9",
   "metadata": {
    "id": "da49e5e9"
   },
   "source": [
    "# Model Nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9069a22",
   "metadata": {
    "id": "d9069a22"
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717580b",
   "metadata": {
    "id": "b717580b"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_prob):\n",
    "    assert y_true.ndim == 1 and y_prob.ndim == 1\n",
    "    y_prob = y_prob > 0.5\n",
    "    return (y_true == y_prob).sum().item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ee8df",
   "metadata": {
    "id": "af9ee8df"
   },
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, optimizer, criterion):\n",
    "    start = time.time()\n",
    "    tr_loss = np.zeros((num_epochs))\n",
    "    te_loss = np.zeros((num_epochs))\n",
    "\n",
    "    tr_acc = np.zeros((num_epochs))\n",
    "    te_acc = np.zeros((num_epochs))\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "#         train_loss = test_loss = train_acc = test_acc = 0\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        train_acc = 0\n",
    "        test_acc = 0\n",
    "     \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            print(\"a\")\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            print(\"b\")\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            print(\"c\")\n",
    "            outputs = model(data)\n",
    "            print(\"d\")\n",
    "            loss = criterion(outputs,  labels.type(torch.float32))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_accuracy(labels, outputs)\n",
    "       \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, labels in test_loader:\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "                outputs = outputs.squeeze()\n",
    "                \n",
    "                loss = criterion(outputs,  labels.type(torch.float32))\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                test_acc += get_accuracy(labels, outputs)\n",
    "                  \n",
    "\n",
    "        # compute the average loss and accuracy for each epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        test_loss /= len(test_loader)\n",
    "        train_acc /= len(train)\n",
    "        test_acc /= len(test)\n",
    "\n",
    "        tr_loss[epoch] = train_loss\n",
    "        te_loss[epoch] = test_loss\n",
    "        tr_acc[epoch] = train_acc\n",
    "        te_acc[epoch] = test_acc\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "          best_acc = test_acc\n",
    "          best_model = model\n",
    "          print(f\"BEST SO FAR: {round(best_acc,4)}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    time_spent = time.time()-start\n",
    "    print(f\"Time spent {round(time_spent, 2)}, Time per Epoch {round(time_spent/num_epochs, 2)}\")\n",
    "\n",
    "    plt.plot(tr_acc, label='Train accuracy')\n",
    "    plt.plot(te_acc, label='Test accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(tr_loss, label='Train accuracy')\n",
    "    plt.plot(te_loss, label='Test accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87faf06b",
   "metadata": {
    "id": "87faf06b"
   },
   "source": [
    "## CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd12761",
   "metadata": {
    "id": "fdd12761"
   },
   "outputs": [],
   "source": [
    "class net_CNN_1(nn.Module):\n",
    "    def __init__(self, channels, feature_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 3, 2, 1), #300x300 -> 75x75 \n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1), # 75x75 -> 19x19\n",
    "            self.block(feature_size*2, feature_size*4, 3, 2, 1), # 19x19 -> 5x5\n",
    "            self.block(feature_size*4, feature_size*8, 3, 2, 1), #5x5 -> 1x1\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(feature_size*8, 8), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(8, 4), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x).squeeze()\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c84fc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1673121535394,
     "user": {
      "displayName": "julian wallis",
      "userId": "17524896017552644151"
     },
     "user_tz": -60
    },
    "id": "33c84fc9",
    "outputId": "062be809-9bc6-4638-bc9c-1b9accb9fd29"
   },
   "outputs": [],
   "source": [
    "lr_CNN_1 = 0.01\n",
    "feature_size_CNN_1 = 2\n",
    "num_epochs_CNN_1 = 50\n",
    "\n",
    "CNN_1 = net_CNN_1(channels, feature_size_CNN_1).to(device)\n",
    "CNN_1.apply(weights_init)\n",
    "\n",
    "criterion_CNN_1 = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer_CNN_1 = torch.optim.SGD(CNN_1.parameters(), lr=lr_CNN_1, momentum=0.9)\n",
    "\n",
    "pytorch_total_params_CNN_1 = sum(p.numel() for p in CNN_1.parameters())\n",
    "print(\"Total number of parameters CNN: \", pytorch_total_params_CNN_1)\n",
    "# summary(CNN_1, (3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7a04b",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4b7a04b",
    "outputId": "a57e7239-c5ae-49a7-fc3f-e825276fb329"
   },
   "outputs": [],
   "source": [
    "best_CNN_1, acc = train_model(CNN_1, num_epochs_CNN_1, optimizer_CNN_1, criterion_CNN_1)\n",
    "\n",
    "print(f\"Saving best CNN_1 with accuracy {round(acc,4)}\")\n",
    "torch.save(best_CNN_1.state_dict(), \"/content/drive/My Drive/practica2/models/CNN1/\"+str(round(acc, 4))+\".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54ad31",
   "metadata": {
    "id": "1b54ad31"
   },
   "source": [
    "## CNN_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a7efa",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "065a7efa"
   },
   "outputs": [],
   "source": [
    "class net_CNN_2(nn.Module):\n",
    "    def __init__(self, channels, feature_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 5, 3, 0), #300x300 -> 100x100\n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1), #100x100 -> 50x50\n",
    "            self.block(feature_size*2, feature_size*4, 5, 3, 1), # 50x50 -> 16x16\n",
    "            self.block(feature_size*4, feature_size*8, 5, 3, 1), # 16x16 -> 5x5\n",
    "            self.block(feature_size*8, feature_size*4, 3, 2, 1), # 5x5 -> 3x3\n",
    "            self.block(feature_size*4, feature_size*2, 3, 2, 1), # 3x3 -> 2x2\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(feature_size*2*2*2, feature_size*2*2), # 16 -> 8\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(feature_size*2*2, feature_size*2), # 8 -> 4 \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(feature_size*2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x).squeeze()\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365ccf8",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6365ccf8",
    "outputId": "291aaa80-bbc5-4212-f7ac-78febd961496"
   },
   "outputs": [],
   "source": [
    "lr_CNN_2 = 0.003\n",
    "feature_size_CNN_2 = 2\n",
    "num_epochs_CNN_2 = 50\n",
    "\n",
    "CNN_2 = net_CNN_2(channels, feature_size_CNN_2).to(device)\n",
    "CNN_2.apply(weights_init)\n",
    "\n",
    "criterion_CNN_2 = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer_CNN_2 = torch.optim.SGD(CNN_2.parameters(), lr=lr_CNN_2, momentum = 0.5, nesterov = True)\n",
    "\n",
    "pytorch_total_params_CNN_2 = sum(p.numel() for p in CNN_2.parameters())\n",
    "print(\"Total number of parameters: \", pytorch_total_params_CNN_2)\n",
    "summary(CNN_2, (3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df0bbc",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b0df0bbc",
    "outputId": "5d907b08-43fe-4d1d-b208-63420013c6f0"
   },
   "outputs": [],
   "source": [
    "best_CNN_2, acc = train_model(CNN_2, num_epochs_CNN_2, optimizer_CNN_2, criterion_CNN_2)\n",
    "\n",
    "print(f\"Saving best CNN2 with accuracy {round(acc,4)}\")\n",
    "torch.save(best_CNN_2.state_dict(), \"/content/drive/My Drive/practica2/models/CNN2/\"+str(round(acc, 4))+\".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d2d30",
   "metadata": {
    "id": "283d2d30"
   },
   "source": [
    "## FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33079dc",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a33079dc"
   },
   "outputs": [],
   "source": [
    "class net_FCN(nn.Module):\n",
    "    def __init__(self, channels, feature_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 5, 3, 0), # 300x300 --> 99x99\n",
    "            self.block(feature_size, feature_size*2, 5, 3, 0), # 99x99 --> 32x32\n",
    "            self.block(feature_size*2, feature_size*4, 5, 3, 0), # 32x32 --> 10x10\n",
    "            self.block(feature_size*4, feature_size*2, 3, 2, 1), # 10x10 --> 5x5\n",
    "            self.block(feature_size*2, feature_size, 3, 2, 1), # 5x5 --> 3x3\n",
    "            nn.Conv2d(feature_size, 1, 3, 2, 0) # 3x3 -> 1x1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x).squeeze()\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef844c",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1fef844c",
    "outputId": "7232cd09-f8e0-442c-c4ce-8f7f70db112e"
   },
   "outputs": [],
   "source": [
    "lr_FCN = 0.002\n",
    "feature_size_FCN = 2\n",
    "num_epochs_FCN = 50\n",
    "\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "FCN = net_FCN(channels, feature_size_FCN).to(device)\n",
    "FCN.apply(weights_init)\n",
    "\n",
    "criterion_FCN = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer_FCN = torch.optim.SGD(FCN.parameters(), lr=lr_FCN, momentum=0.5)\n",
    "\n",
    "pytorch_total_params_FCN = sum(p.numel() for p in FCN.parameters())\n",
    "print(\"Total number of parameters FCN: \", pytorch_total_params_FCN)\n",
    "summary(FCN, (3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576feeb1",
   "metadata": {
    "id": "576feeb1"
   },
   "outputs": [],
   "source": [
    "best_FCN, acc = train_model(FCN, num_epochs_FCN, optimizer_FCN, criterion_FCN)\n",
    "\n",
    "print(f\"Saving best FCN with accuracy {round(acc,4)}\")\n",
    "torch.save(best_FCN.state_dict(), \"/content/drive/My Drive/practica2/models/FCNN/\"+str(round(acc, 4))+\".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b61fb",
   "metadata": {
    "id": "5d6b61fb"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b0e9f",
   "metadata": {
    "id": "5d4b0e9f"
   },
   "outputs": [],
   "source": [
    "# AÑADIR SIGMOID\n",
    "\n",
    "class net_Ensemble(torch.nn.Module):\n",
    "    def __init__(self, cnn1, cnn2, fcn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = cnn1\n",
    "        self.cnn2 = cnn2\n",
    "        self.fcn1 = fcn\n",
    "       \n",
    "        self.fc = nn.Linear(3, 1)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        # freeze the weights of the pre-trained models\n",
    "        for param in self.cnn1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.cnn2.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.fcn1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        X_1 = self.sig(self.cnn1(data))\n",
    "        X_2 = self.sig(self.cnn2(data))\n",
    "        X_3 = self.sig(self.fcn1(data))\n",
    "        \n",
    "        X = torch.stack([X_1, X_2, X_3], dim=1)\n",
    "        X = self.fc(F.relu(X))\n",
    "   \n",
    "        return X.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69bdce",
   "metadata": {
    "id": "5f69bdce"
   },
   "outputs": [],
   "source": [
    "lr_Ensemble = 0.1\n",
    "\n",
    "num_epochs_Ensemble = 50\n",
    "\n",
    "model1 = net_CNN_1(3,2)\n",
    "model2 = net_CNN_2(3,2)\n",
    "model3 = net_FCN(3,2)\n",
    "\n",
    "model1.load_state_dict(torch.load(\"/content/drive/My Drive/practica2/models/CNN1/0.9048.pth\"))\n",
    "model2.load_state_dict(torch.load(\"/content/drive/My Drive/practica2/models/CNN2/0.9394.pth\"))\n",
    "model3.load_state_dict(torch.load(\"/content/drive/My Drive/practica2/models/FCNN/0.8918.pth\"))\n",
    "\n",
    "ensemble = net_Ensemble(model1, model2, model3).to(device)\n",
    "\n",
    "# ensemble = net_Ensemble(CNN_1, CNN_2, FCN).to(device)\n",
    "\n",
    "ensemble.apply(weights_init)\n",
    "\n",
    "criterion_Ensemble= nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "optimizer_Ensemble = torch.optim.SGD(ensemble.parameters(), lr=lr_Ensemble, momentum = 0.9)\n",
    "\n",
    "pytorch_total_params_Ensemble = sum(p.numel() for p in ensemble.parameters())\n",
    "pytorch_learn_params_Ensemble = sum(p.numel() for p in ensemble.parameters() if p.requires_grad)\n",
    "print(\"Total number of parameters ensemble: \", pytorch_total_params_Ensemble)\n",
    "print(\"Number of learnable parameters ensemble: \", pytorch_learn_params_Ensemble)\n",
    "\n",
    "summary(ensemble, (3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6c569",
   "metadata": {
    "id": "80f6c569"
   },
   "outputs": [],
   "source": [
    "best_ensemble, acc = train_model(ensemble, num_epochs_Ensemble, optimizer_Ensemble, criterion_Ensemble)\n",
    "\n",
    "print(f\"Saving best ENSEMBLE with accuracy {round(acc,4)}\")\n",
    "torch.save(best_ensemble.state_dict(), \"/content/drive/My Drive/practica2/models/ENSEMBLE/\"+str(round(acc, 4))+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491adda",
   "metadata": {
    "id": "8491adda"
   },
   "outputs": [],
   "source": [
    "print(best_ensemble.fc[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd4bee",
   "metadata": {
    "id": "d9dd4bee"
   },
   "outputs": [],
   "source": [
    "model1 = net_CNN_1(3,2)\n",
    "model1.load_state_dict(torch.load(\"models/CNN1_1.pth\"))\n",
    "\n",
    "model2 = net_CNN_2(3,2)\n",
    "model2.load_state_dict(torch.load(\"models/CNN2_1.pth\"))\n",
    "\n",
    "model3 = net_FCN(3,2)\n",
    "model3.load_state_dict(torch.load(\"models/FCN_1.pth\"))\n",
    "\n",
    "model4 = net_Ensemble(model1, model2, model3)\n",
    "model4.load_state_dict(torch.load(\"models/Ensemble_1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1fb5c",
   "metadata": {
    "id": "96b1fb5c"
   },
   "outputs": [],
   "source": [
    "real_human = CustomDataset(path = \"/content/drive/My Drive/practica2/real/human/\", transform=transform)\n",
    "real_horse = CustomDataset(path = \"/content/drive/My Drive/practica2/real/horse/\", transform=transform)\n",
    "\n",
    "loader_human = DataLoader(real_human, batch_size=64)\n",
    "loader_horse = DataLoader(real_horse, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2235be4",
   "metadata": {
    "id": "e2235be4"
   },
   "outputs": [],
   "source": [
    "# Loop through the human data\n",
    "acc1 = acc2 = acc3 = acc4 = 0\n",
    "for i, (data, labels) in enumerate(loader_human):\n",
    "    # Get the inputs and labels\n",
    "    # Make predictions with the models\n",
    "    output1 = model1(data)\n",
    "    output2 = model2(data)\n",
    "    output3 = model3(data)\n",
    "    output4 = model4(data)\n",
    "\n",
    "    acc1 += get_accuracy(labels, output1)\n",
    "    acc2 += get_accuracy(labels, output2)\n",
    "    acc3 += get_accuracy(labels, output3)\n",
    "    acc4 += get_accuracy(labels, output4)\n",
    "\n",
    "acc1 = round(acc1 / len(real_human), 4)\n",
    "acc2 = round(acc2 / len(real_human), 4)\n",
    "acc3 = round(acc3 / len(real_human), 4)\n",
    "acc4 = round(acc4 / len(real_human), 4)\n",
    "    # Print the predictions\n",
    "print(\"Accuracy for real humans:\")\n",
    "print(f\"CNN1 {acc1}, CNN2 {acc2}, FCNN {acc3}, Ensemble {acc4}\")\n",
    "      \n",
    "acc1 = acc2 = acc3 = acc4 = 0\n",
    "for i, (data, labels) in enumerate(loader_horse):\n",
    "    # Get the inputs and labels\n",
    "    # Make predictions with the models\n",
    "    output1 = model1(data)\n",
    "    output2 = model2(data)\n",
    "    output3 = model3(data)\n",
    "    output4 = model4(data)\n",
    "\n",
    "    acc1 += get_accuracy(labels, output1)\n",
    "    acc2 += get_accuracy(labels, output2)\n",
    "    acc3 += get_accuracy(labels, output3)\n",
    "    acc4 += get_accuracy(labels, output4)\n",
    "\n",
    "acc1 = round(acc1 / len(real_horse), 4)\n",
    "acc2 = round(acc2 / len(real_horse), 4)\n",
    "acc3 = round(acc3 / len(real_horse), 4)\n",
    "acc4 = round(acc4 / len(real_horse), 4)\n",
    "    # Print the predictions\n",
    "print(\"Accuracy for real horses:\")\n",
    "print(f\"CNN1 {acc1}, CNN2 {acc2}, FCNN {acc3}, Ensemble {acc4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8184b",
   "metadata": {
    "id": "6bc8184b"
   },
   "outputs": [],
   "source": [
    "# Loop through the human data\n",
    "acc1 = acc2 = acc3 = acc4 = 0\n",
    "for i, (data, labels) in enumerate(loader_human):\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    output1 = CNN_1(data)\n",
    "    output2 = CNN_2(data)\n",
    "    output3 = FCN(data)\n",
    "    output4 = model(data)\n",
    "\n",
    "    acc1 += get_accuracy(labels, output1)\n",
    "    acc2 += get_accuracy(labels, output2)\n",
    "    acc3 += get_accuracy(labels, output3)\n",
    "    acc4 += get_accuracy(labels, output4)\n",
    "\n",
    "acc1 = round(acc1 / len(real_human), 4)\n",
    "acc2 = round(acc2 / len(real_human), 4)\n",
    "acc3 = round(acc3 / len(real_human), 4)\n",
    "acc4 = round(acc4 / len(real_human), 4)\n",
    "    # Print the predictions\n",
    "print(\"Accuracy for real humans:\")\n",
    "print(f\"CNN1 {acc1}, CNN2 {acc2}, FCNN {acc3}, Ensemble {acc4}\")\n",
    "      \n",
    "acc1 = acc2 = acc3 = acc4 = 0\n",
    "for i, (data, labels) in enumerate(loader_horse):\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    output1 = CNN_1(data)\n",
    "    output2 = CNN_2(data)\n",
    "    output3 = FCN(data)\n",
    "    output4 = model(data)\n",
    "\n",
    "    acc1 += get_accuracy(labels, output1)\n",
    "    acc2 += get_accuracy(labels, output2)\n",
    "    acc3 += get_accuracy(labels, output3)\n",
    "    acc4 += get_accuracy(labels, output4)\n",
    "\n",
    "acc1 = round(acc1 / len(real_horse), 4)\n",
    "acc2 = round(acc2 / len(real_horse), 4)\n",
    "acc3 = round(acc3 / len(real_horse), 4)\n",
    "acc4 = round(acc4 / len(real_horse), 4)\n",
    "    # Print the predictions\n",
    "print(\"Accuracy for real horses:\")\n",
    "print(f\"CNN1 {acc1}, CNN2 {acc2}, FCNN {acc3}, Ensemble {acc4}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a3f1cc4cb12d314308f93e8d7f4e89eeb6743400550d62b7d846e6683a05f7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
