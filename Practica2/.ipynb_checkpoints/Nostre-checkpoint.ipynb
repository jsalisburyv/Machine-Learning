{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf12ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de74b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693375ea",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e4de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.files_paths = [f for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.data = [Image.open(os.path.join(self.path, f)).convert('RGB') for f in os.listdir(self.path) if f.endswith('.png')]\n",
    "        self.labels = [f.split('-')[0] for f in self.files_paths]\n",
    "        self.labels = [0 if x == 'horse' else 1 for x in self.labels]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # image = transforms.ToTensor()(image)\n",
    "        # image = image.permute(1, 2, 0)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5efd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_normalization_values(path):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation of the pixel values for each channel\n",
    "    in the images stored in the specified folder.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.png'):\n",
    "            image = Image.open(os.path.join(path, file))\n",
    "            image_np = np.array(image)\n",
    "\n",
    "            red, green, blue = image_np[:,:,0], image_np[:,:,1], image_np[:,:,2]\n",
    "\n",
    "            red_values.append(red)\n",
    "            green_values.append(green)\n",
    "            blue_values.append(blue)\n",
    "\n",
    "    red_mean = np.mean(red_values)/255\n",
    "    green_mean = np.mean(green_values)/255\n",
    "    blue_mean = np.mean(blue_values)/255\n",
    "\n",
    "    red_std = np.std(red_values)/255\n",
    "    green_std = np.std(green_values)/255\n",
    "    blue_std = np.std(blue_values)/255\n",
    "\n",
    "    return (red_mean, green_mean, blue_mean), (red_std, green_std, blue_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39054741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std = get_normalization_values(\"data/train/\")\n",
    "\n",
    "# mean = torch.tensor(mean)\n",
    "# std = torch.tensor(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f916a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train = CustomDataset(path = \"data/train/\",  transform=transform)\n",
    "test = CustomDataset(path = \"data/validation/\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=train_batch_size, shuffle=True, pin_memory = True)\n",
    "test_loader = DataLoader(test, batch_size=test_batch_size, shuffle=True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8938e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first batch of data from the data loader\n",
    "# batch = next(iter(train_loader))\n",
    "# data, labels = batch\n",
    "\n",
    "# # Make a figure with subplots\n",
    "# fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "\n",
    "# # Iterate over the data and labels and plot the images\n",
    "# for i, (data, label) in enumerate(zip(data, labels)):\n",
    "#     # Calculate the row and column indices for the subplot\n",
    "#     data = np.squeeze(data)\n",
    "\n",
    "#     row = i // 8\n",
    "#     col = i % 8\n",
    "#     # Plot the image on the corresponding subplot\n",
    "#     ax = axs[row, col]\n",
    "#     ax.imshow(data)\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49e5e9",
   "metadata": {},
   "source": [
    "# Model Nostre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9069a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd12761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_CNN(nn.Module):\n",
    "    def __init__(self, channels, feature_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 3, 2, 1),\n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1),\n",
    "            self.block(feature_size*2, feature_size*4, 3, 2, 1),\n",
    "            self.block(feature_size*4, feature_size*8, 3, 2, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a33079dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_FCN(nn.Module):\n",
    "    def __init__(self, channels, feature_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            self.block(channels, feature_size, 3, 2, 1), # 300x300 --> 150x150\n",
    "            self.block(feature_size, feature_size*2, 3, 2, 1), # 150x150 --> 75x75\n",
    "            self.block(feature_size*2, feature_size*4, 3, 2, 1), # 75x75 --> 38x38\n",
    "            self.block(feature_size*4, feature_size*8, 3, 2, 1), # 38x38 --> 19x19\n",
    "            self.block(feature_size*8, feature_size*4, 3, 2, 1), # 19x19 --> 10x10\n",
    "            self.block(feature_size*4, feature_size*2, 3, 2, 1), # 10x10 --> 5x5\n",
    "            self.block(feature_size*2, feature_size, 3, 2, 1), # 5x5 --> 3x3\n",
    "            self.block(feature_size, 1, 3, 2, 0), # 3x3 --> 2x2\n",
    "            nn.Flatten(),\n",
    "            nn.Softmax(dim=1)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33c84fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\walli\\miniconda3\\envs\\pyAA\\lib\\site-packages\\torch\\autograd\\profiler.py:176: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SGD' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m criterion_CNN \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m criterion_FCN \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 26\u001b[0m optimizer_CNN \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_CNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_CNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[0;32m     27\u001b[0m optimizer_FCN \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net_FCN\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr_FCN, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGD' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "lr_CNN = 0.001\n",
    "lr_FCN = 0.01\n",
    "\n",
    "channels = 3\n",
    "\n",
    "feature_size_CNN = 2\n",
    "feature_size_FCN = 2\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "num_epochs_CNN = 5\n",
    "num_epochs_FCN = 50\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        net_CNN = Net_CNN(channels, feature_size_CNN, num_classes).to(device)\n",
    "\n",
    "net_FCN = Net_FCN(channels, feature_size_FCN).to(device)\n",
    "\n",
    "net_CNN.apply(weights_init)\n",
    "net_FCN.apply(weights_init)\n",
    "\n",
    "criterion_CNN = nn.CrossEntropyLoss().to(device)\n",
    "criterion_FCN = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer_CNN = torch.optim.SGD(net_CNN.parameters(), lr=lr_CNN, momentum=0.9).to(device)\n",
    "optimizer_FCN = torch.optim.SGD(net_FCN.parameters(), lr=lr_FCN, momentum=0.9).to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41aa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net_FCN)\n",
    "pytorch_total_params_CNN = sum(p.numel() for p in net_CNN.parameters())\n",
    "pytorch_total_params_FCN = sum(p.numel() for p in net_FCN.parameters())\n",
    "print(\"Total number of parameters CNN: \", pytorch_total_params_CNN)\n",
    "print(\"Total number of parameters FCN: \", pytorch_total_params_FCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cbf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "step_train = 0\n",
    "step_test = 0\n",
    "\n",
    "tr_loss = np.zeros((num_epochs_CNN))\n",
    "te_loss = np.zeros((num_epochs_CNN))\n",
    "\n",
    "tr_acc = np.zeros((num_epochs_CNN))\n",
    "te_acc = np.zeros((num_epochs_CNN))\n",
    "\n",
    "for epoch in range(num_epochs_CNN):\n",
    "\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    net_CNN.train()\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_CNN.zero_grad(set_to_none=True)\n",
    "        outputs = net_CNN(data)\n",
    "        loss = criterion_CNN(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_CNN.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # compute the accuracy for this batch\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / len(labels)\n",
    "        train_acc += accuracy\n",
    "\n",
    "\n",
    "        writer_train.add_scalar(\"Training loss\", loss, global_step=step_train)\n",
    "        step_train += 1\n",
    "    \n",
    "    net_CNN.eval()\n",
    "    with torch.no_grad():\n",
    "        for j, (data, labels) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            labels = torch.tensor(labels)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net_CNN(data)\n",
    "            loss = criterion_CNN(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # compute the accuracy for this batch\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = correct / len(labels)\n",
    "            test_acc += accuracy\n",
    "            \n",
    "            step_test += 1\n",
    "\n",
    "    # compute the average loss and accuracy for each epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "\n",
    "    tr_loss[epoch] = train_loss\n",
    "    te_loss[epoch] = test_loss\n",
    "    tr_acc[epoch] = train_acc\n",
    "    te_acc[epoch] = test_acc\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_CNN}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(tr_acc, label='Train accuracy')\n",
    "plt.plot(te_acc, label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00367ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_test = 0\n",
    "\n",
    "# tr_loss = np.zeros((num_epochs_FCN))\n",
    "# te_loss = np.zeros((num_epochs_FCN))\n",
    "\n",
    "# tr_acc = np.zeros((num_epochs_FCN))\n",
    "# te_acc = np.zeros((num_epochs_FCN))\n",
    "\n",
    "# for epoch in range(num_epochs_FCN):\n",
    "\n",
    "#     train_loss = 0\n",
    "#     test_loss = 0\n",
    "#     train_acc = 0\n",
    "#     test_acc = 0\n",
    "\n",
    "#     net_FCN.train()\n",
    "#     for i, (data, labels) in enumerate(train_loader):\n",
    "#         data, labels = data.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "#         optimizer_FCN.zero_grad(set_to_none=True)\n",
    "#         outputs = net_FCN(data)\n",
    "    \n",
    "#         labels = labels.unsqueeze(1)\n",
    "#         print(outputs, labels)\n",
    "\n",
    "#         loss = F.binary_cross_entropy(outputs,  labels.type(torch.float32))\n",
    "#         loss.backward()\n",
    "#         optimizer_FCN.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         # compute the accuracy for this batch\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         correct = (predicted == labels).sum().item()\n",
    "#         accuracy = correct / len(labels)\n",
    "#         train_acc += accuracy\n",
    "\n",
    "#     net_FCN.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for j, (data, labels) in enumerate(test_loader):\n",
    "#             data, labels = data.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "#             optimizer_FCN.zero_grad(set_to_none=True)\n",
    "#             outputs = net_FCN(data)\n",
    "        \n",
    "#             labels = labels.unsqueeze(1)\n",
    "#             loss = F.binary_cross_entropy(outputs,  labels.type(torch.float32))\n",
    "\n",
    "#             test_loss += loss.item()\n",
    "\n",
    "#             # compute the accuracy for this batch\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct = (predicted == labels).sum().item()\n",
    "#             accuracy = correct / len(labels)\n",
    "#             test_acc += accuracy\n",
    "\n",
    "#     # compute the average loss and accuracy for each epoch\n",
    "#     train_loss /= len(train_loader)\n",
    "#     test_loss /= len(test_loader)\n",
    "#     train_acc /= len(train_loader)\n",
    "#     test_acc /= len(test_loader)\n",
    "\n",
    "#     tr_loss[epoch] = train_loss\n",
    "#     te_loss[epoch] = test_loss\n",
    "#     tr_acc[epoch] = train_acc\n",
    "#     te_acc[epoch] = test_acc\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs_FCN}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "plt.plot(tr_acc, label='Train accuracy')\n",
    "plt.plot(te_acc, label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6fe11",
   "metadata": {},
   "source": [
    "# Model Existent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706533f",
   "metadata": {},
   "source": [
    "https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d569e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 20\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eeb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(num_classes, feature_extract, weights=None):\n",
    "    model = resnet50(weights=weights)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    input_size = 224\n",
    "    return model, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc67c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, input_size = init_model(num_classes, feature_extract)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "02fa8fd54c95af2be9661fa379357b4da443ac0bd23893c8dcfed0cde6713a10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
