{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "78hwtX74aaeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FCN\n",
        "\n",
        "Avui farem feina amb xarxes que no tenen cap tipus de capa _fully connected_ per tant serà una xarxa _Fully Convolutional Network_ (FCN). \n",
        "\n",
        "Emprarem un dataset classic de classificació d'imatges on s'ha de decidir si a una imatge apareix un ca o un moix. Enllaç al [Dataset](https://www.kaggle.com/c/dogs-vs-cats). \n",
        "\n",
        "Emprar aquest dataset ens permetrà veure com hem de procedir si no podem descarregar les dades de manera automàtica emprant la mateixa llibreria.\n"
      ],
      "metadata": {
        "id": "7X7Njio92KFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGq0Ys7EGSTs",
        "outputId": "0639e06a-4fdb-4191-9aff-2715abc80ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "%cd #TODO al vostre sistema de fitxers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkUHh4I4HyEQ",
        "outputId": "c8670a2f-1365-4943-ca58-4f6cd68bc40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content/gdrive/MyDrive/gatigos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descomprimim el conjunt d'entrenament, serà suficient per la feina que hem de fer:\n"
      ],
      "metadata": {
        "id": "c5tcnDdNt0w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip train.zip\n",
        "# !unzip test1.zip # aquest avui no serà necessari"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on3kZ0NdSRvk",
        "outputId": "b7c5c7da-adc5-4311-b60d-5b27190cc8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.zip\n",
            "replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dades\n",
        "Preparam el conjunt de dades, construim una llista amb el nom de totes les imatges"
      ],
      "metadata": {
        "id": "5IUXSYLw07AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_files = os.listdir('train/')\n",
        "img_files = list(filter(lambda x: x != 'train', img_files))\n",
        "img_files = list(map(lambda p: f\"train/{p}\", img_files))\n",
        "\n",
        "print(\"total training images\", len(img_files))\n",
        "\n",
        "\n",
        "random.shuffle(img_files)\n",
        "#TODO: Aquí podeu substituir les X per nombres, d'aquesta manera podeu fer conjunts més grans o més petits.\n",
        "# per entrenar més ràpid o més consistent\n",
        "ttrain = img_files[:XXXXXX] \n",
        "ttest = img_files[XXXXXX:]\n",
        "\n",
        "print(\"train size:\", len(ttrain))\n",
        "print(\"test size:\", len(ttest))"
      ],
      "metadata": {
        "id": "CvBbWj9BZONG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construim el dataset tal com ho hem fet sempre, però ara tota la feina és nostra"
      ],
      "metadata": {
        "id": "2B2JRO5T1ZiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Constructor del dataset.\n",
        "class CatDogDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform):\n",
        "      super().__init__()\n",
        "      self.paths = image_paths\n",
        "      self.len = len(self.paths)\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self): \n",
        "      return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      path = self.paths[index]\n",
        "      image = Image.open(path).convert('RGB')\n",
        "      image = self.transform(image)\n",
        "      label = 0 if 'cat' in path else 1\n",
        "      return (image, label)\n",
        "\n",
        "\n",
        "# creació dels conjunts d'entrenament i test\n",
        "train_ds = CatDogDataset(ttrain, transform)\n",
        "test_ds = CatDogDataset(ttest, transform)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=100)\n",
        "test_dl = DataLoader(test_ds, batch_size=100)\n",
        "\n",
        "\n",
        "\n",
        "#batch = next(iter(test_ds))\n",
        "#batch[0].shape"
      ],
      "metadata": {
        "id": "JiVfQJ0ZbzD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xarxa\n",
        "Com sempre, vosaltres us encarregau de dissenyar la xarxa:"
      ],
      "metadata": {
        "id": "kUKSc7YL3kNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CatAndDogConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CatAndDogConvNet, self).__init__()\n",
        "        \n",
        "        #TODO\n",
        "\n",
        "        self.sigmoide = nn.Sigmoid()\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # TODO\n",
        "        \n",
        "        x = self.sigmoide(x)\n",
        "        \n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "Jo2R5YE8ifMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenament"
      ],
      "metadata": {
        "id": "NQVfN-vD3uPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    loss_v = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "      \n",
        "        loss = # TODO\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0 and verbose:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Average: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(), loss.item()/ len(data)))\n",
        "        loss_v += loss.item()\n",
        "\n",
        "    loss_v /= len(train_loader.dataset)\n",
        "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
        " \n",
        "    return loss_v\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            \n",
        "            \n",
        "            test_loss += #TODO\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        " \n",
        "  \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "3WqMHALIoN1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenament"
      ],
      "metadata": {
        "id": "-3yxe2hX4eGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = False\n",
        "torch.manual_seed(33)\n",
        "\n",
        "if use_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "epochs = # TODO\n",
        "lr = #TODO\n",
        "\n",
        "model = CatAndDogConvNet().to(device)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
        "\n",
        "print(\"Parameters \",pytorch_total_params)\n",
        "optimizer = # TODO\n",
        "\n",
        "# Guardam el valor de peèrdua mig de cada iteració (època)\n",
        "train_l = np.zeros((epochs))\n",
        "test_l = np.zeros((epochs))\n",
        "\n",
        "# Bucle d'entrenament\n",
        "for epoch in range(0, epochs):\n",
        "    train_l[epoch] = train(model, device, train_dl, optimizer, epoch)\n",
        "    test_l[epoch]  = test(model, device, test_dl)\n"
      ],
      "metadata": {
        "id": "8jGCuUhwoR7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validació"
      ],
      "metadata": {
        "id": "YaBP84cn4tPK"
      }
    }
  ]
}