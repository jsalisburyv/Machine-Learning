{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629fbe0b",
   "metadata": {},
   "source": [
    "# Pràctica 2 - Perceptron\n",
    "\n",
    "**Adaline: Batch i Stochastic gradient descent**\n",
    "\n",
    "ADAptative Linear NEuron (Adaline) representa un algorisme diferent al presentat per _Rosenblatt_ per xarxes d'una sola neurona.\n",
    "\n",
    "Aquest algorisme és important, ja que mostra el concepte de _definició i minimització de funcions de cost_. La diferència entre Adaline i el perceptron presentat per _Rosenblatt_ és que els pesos de la neurona s'actualitzen mitjançant una funció d'activació lineal en lloc d'una funció escaló.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1b04f",
   "metadata": {},
   "source": [
    "## Teoría bàsica\n",
    "\n",
    "La **funció d'activació lineal** $\\phi(z)$ és la funció de l'entrada de la xarxa: $\\phi(w^Tx) = w^Tx$, aquesta funció és la que s'empra per aprendre els pesos de la xarxa. Per altra banda, utilitzarem una funció similar a la funció escaló per determinar la classe d'una mostra.\n",
    "\n",
    "\n",
    "La **funció objectiu**, és una funció de cost que volem minimitzar. En aquest cas és la funció $J$ que aprèn els pesos com la suma dels errors quadrats entre la sortida de la xarxa i el _groundtruth_: $$J(w) = 1/2\\sum_i(y^{(i)} - \\phi(z^{(i)}))^2$$\n",
    "\n",
    "L'ús d'aquesta funció contínua vé motivada perquè aquesta és diferenciable i convexa. Això implica que podem aplicar\n",
    "l'algorisme del **descens de gradient** per trobar els pesos que la minimitzen.  El descens del gradient és el mètode estàndard utilitzat per minimitzar una funció de pèrdua o error, és a dir, reduir la diferència entre el resultat obtingut i aquell que es cerca obtenir. Cal recordar que: el gradient representa la pendent de la recta tangent a la gràfica d'una funció en un punt.\n",
    "\n",
    "\n",
    "![image](imatges/02_minimitzacio.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedc56b",
   "metadata": {},
   "source": [
    "## Algorisme\n",
    "\n",
    "L'algorisme es resumeix en les següents pases:\n",
    "\n",
    "1. Inicialitzar els pesos a valor 0 (o a nombre aleatori prou petit).\n",
    "2. Fer $n$ iteracions on, a cada iteració ajustarem/actualitzarem els pesos $\\mathbf{w}$.\n",
    "3. Calcular la classe de sortida (predicció) *final* de la xarxa $\\hat y$.\n",
    "\n",
    "### Actualitzar el vector de pesos\n",
    "\n",
    "L'actualització del vector de pesos $w$ es pot expressar de la següent manera:\n",
    "\n",
    "$$w = w + \\Delta w$$\n",
    "\n",
    "On el valor de $\\Delta w_j$ es defineix com el gradient negatiu multiplicat per la ratio d'aprenentage $\\eta$:\n",
    "\n",
    "$$\\Delta w = -\\eta \\nabla J (w)$$\n",
    "\n",
    "Cal tenir en compte que per calcular el gradient de la funció de cost s'ha de calcular la seva derivada parcial.\n",
    "\n",
    "Segons quina sigui la nostra política d'actualització:\n",
    "    \n",
    "* **Batch gradient:** Enlloc d'actualitzar els pesos a cada exemple (com a l'algorisme de Rosenblatt) aquests s'actualitzen un cop per tot el conjunt d'entrenament a cada iteració de l'algorisme. Tot el còmput es pot realitzar mitjançant una multiplicació de matrius.\n",
    "\n",
    "$$ \\Delta w = -\\eta (y^{(i)} - \\phi(z^{(i)}))x^{(i)} $$\n",
    "\n",
    "* **Stochastic gradient descent** (SGD): Actualitza els pesos a cada mostra del conjunt d'entrenament, aconseguint la convergència al valor mínim més ràpid, a causa del major rati d'actualització dels pesos. Per obtenir bons resultats és important que l'ordre en què computam les mostres del conjunt d'entrenament sigui aleatori a cada iteració per evitar cicles.\n",
    "\n",
    "\n",
    "$$ \\Delta w = -\\eta \\sum_i(y^{(i)} - \\phi(z^{(i)}))x^{(i)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8f11d",
   "metadata": {},
   "source": [
    "### Notes finals\n",
    "\n",
    "* El descens de gradient es beneficia de treballar amb dades estandaritzades. Amb $\\mu = 0$ i $\\sigma = 1$. A scikit teniu la funció [Standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standard%20scaler#sklearn-preprocessing-standardscaler).\n",
    "* El descens de gradient Stochastic es pot emprar per fer aprenentatge _online_, ja que podem afegir nous exemples i tornar a fer un procés d'entrenament a partir dels pesos que ja teníem. Per altra banda, el temps d'entrenament és major, perquè, no ens podem beneficiar de les operacions en forma matricial.\n",
    "* Per fer l'entrenament amb SGD es recomana mesclar aleatòriament les dades per evitar reproduir cicles.\n",
    "* Existeix una alternativa mixta als dos algorismes presentats, aquesta és coneguda com a **mini-batch** learning. Aquest mètode consisteix a aplicar la tècnica de Batch gradient a petits grups d'elements del conjunt d'entrenament. D'aquesta manera aprofitam la capacitat de fer operacions matricials del Batch learning amb la capacitat d'actualitzar els pesos més ràpid del Stochastic gradient descent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba186064",
   "metadata": {},
   "source": [
    " # Feina a fer\n",
    "\n",
    " 0. Entendre l'algorisme del Descens del gradient.\n",
    " 1. Implementar el mètode _fit_ (mode batch).\n",
    " 2. Fer les tasques que trobareu al fitxer _main_.\n",
    " 3. **Extra:** Modificar la classe Adaline per obtenir l'error quadratic mitjà a cada iteració de l'algorisme (mostrar-ho en una gráfica)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aprenentatge_automatic]",
   "language": "python",
   "name": "conda-env-aprenentatge_automatic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
