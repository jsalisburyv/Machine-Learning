{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pràctica - El marc de l'aprenentatge automàtic:\n",
    "\n",
    "El procés d'aplicar tècniques d'aprenentatge és un procés que consta de cinc parts:\n",
    "\n",
    "- Tractament de les dades: preparació del conjunt de dades, selecció de característiques, **obtenció dels conjunts d'entrenament / test**.\n",
    "\n",
    "- **Selecció de la / les mètriques adients**.\n",
    "\n",
    "- **Selecció de la tècnica d'aprenentatge automàtic**.\n",
    "\n",
    "- **Avaluació del model**.\n",
    "\n",
    "- **Ajustament del model**.\n",
    "\n",
    "\n",
    "## Separació del conjunt de dades: validació creuada per avaluar el rendiment del nostre model\n",
    "\n",
    "### Mètode _holdout_\n",
    "\n",
    "Aquest mètode consisteix a separar el conjunt de dades en tres subconjunts diferents: entrenament, validació i _test_. El conjunt d'entrenament s'usa com és habitual és a dir per entrenar els diferents models. El conjunt de validació s'usa per seleccionar el millor dels models. El conjunt de _test_, que no usem en cap cas durant el procés d'entrenament, ens servirà per obtenir una idea poc esbiaixada de la capacitat del model d'adaptar-se a noves mostres, sobre aquest conjunt de dades serà sobre el qual obtindrem les mètriques finals del model.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "![](imatges/holdout.png)\n",
    "\n",
    "Aquest mètode encara que senzill d'emprar té un desavantatge, ja que el rendiment del model depen de com hem fet la partició de les dades.\n",
    "\n",
    "### Mètode _K-Fold_\n",
    "\n",
    "Aquesta tècnica és més robusta, ja que repetim el mètode anterior _k_ vegades en _k_ subconjunts del conjunt d'entrenament, per tant, obtenim _k_ models i el mateix nombre de mesures de rendiment. El resultat final s'obtè amb la mitjana de cada una de les repeticions realitzades, d'aquesta manera els resultats depenen manco de les particions que realitzem.\n",
    "\n",
    "Aquesta tècnica normalment s'usa per obtenir els millors paràmetres del model a aplicar, es a dir trobar aquells paràmetres que maximitzen el rendiment de la mètrica que volem usar. Un cop que tenim els millors paràmetres, reentrenam el model emprant el conjunt d'entrenament complet i obtenim les mètriques amb el conjunt de _test_.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "<img src=\"imatges/Kfold.png\" alt=\"kfold\" width=\"600\"/>\n",
    "\n",
    "La pregunta que ens podem fer és: Com seleccionar aquest paràmetre _k_ de forma correcta?\n",
    "\n",
    "Finalment, existeix una variant d'aquesta tècnica anomenada _stratified k-fold_ en el que les proporcions entre classes es mantenen a cada una de les iteracions, això és important quan tenim problemes desbalancejats.\n",
    "\n",
    "## Selecció de mètriques\n",
    "\n",
    "Un cop entrenat el nostre model, tenim la necessitat d'avaluar els resultats obtinguts amb aquest amb alguna mesura que sigui objectiva. Les mesures que explicarem en aquesta secció es calculen a partir d'una matriu de confusió que ens permet guardar quatre mesures bàsiques a partir de considerar que una de les classes és la positiva i l'altra és la negativa.\n",
    "\n",
    "- _True Positives_ (TP): L'algorisme classifica una mostra de la classe positiva com a membre de la classe positiva.\n",
    "- _True Negatives_ (TN): L'algorisme classifica una mostra de la classe negativa com a membre de la classe negativa.\n",
    "- _False Positives_ (FP): L'algorisme classifica una mostra de la classe negativa com a membre de la classe positiva.\n",
    "- _False Negatives_ (FN): L'algorisme classifica una mostra de la classe positiva com a membre de la classe negativa.\n",
    "\n",
    "Podem observar la matriu de confusió en el següent esquema:\n",
    "\n",
    "![image](imatges/confusion_matrix.png \"font: Python Machine Learning\")\n",
    "\n",
    "Aquesta matriu es pot obtenir de manera senzilla usant la funció `confusion_matrix` de la llibreria [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion%20matrix#sklearn-metrics-confusion-matrix)\n",
    "i es pot visualitzar amb la funció [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html?highlight=confusion%20matrix#sklearn-metrics-confusionmatrixdisplay)\n",
    "\n",
    "A partir d'aquestes mesures de primer ordre en podem treure d'altres més completes com l'error o l'exactitud, també es coneix com _Accuracy_.\n",
    "\n",
    "$$ Error = \\frac{FP+FN}{FP+FN+TP+TN}$$\n",
    "<br>\n",
    "$$ Exactitut = \\frac{TP+TN}{FP+FN+TP+TN} = 1 - Error$$\n",
    "\n",
    "Per altra banda, tenim les mesures Rati de Vertaders Positius (_True Positive Rate_, TPR) i la Ratio de Falsos Positius (_False Positive Rate_, FPR) que estan dissenyades per problemes on hi ha una classe amb més mostres que l'altra:\n",
    "\n",
    "$$ FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN} $$\n",
    "<br>\n",
    "$$ TPR = \\frac{TP}{P} = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Finalment, parlarem de precisió (_precision_) i la sensibilitat (_recall_) relacionades amb les ratios de vertaders positius i vertaders negatius:\n",
    "\n",
    "$$ Precisio = \\frac{TP}{TP+FP}$$\n",
    "<br>\n",
    " $$ Sensibilitat = TPR = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Tenim una mesura que engloba aquestes mesures anteriors:\n",
    "\n",
    "$$ F1 = 2 \\frac{Precisio \\times Sensibilitat}{Precisio + Sensibilitat}$$\n",
    "\n",
    "Per sort tenim un mòdul anomenat _metrics_ on hi ha totes aquestes (i d'altres) mètriques ja implementades.\n",
    "\n",
    "## Un exemple complet\n",
    "\n",
    "A continuació teniu un exemple que resumeix el procés sencer emprant la llibreria `Scikit-learn`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114   3]\n",
      " [  1  82]]\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=1, class_sep=2,\n",
    "                           random_state=5)\n",
    "\n",
    "# Tractament de les dades: Separació i estandaritzat\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenament i predicció, aquí no hi ha ajustament de paràmetres\n",
    "clf = SGDClassifier(loss=\"perceptron\", eta0=1, max_iter=1000, learning_rate=\"constant\", random_state=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "prediction = clf.predict(X_test_scaled)\n",
    "\n",
    "# Avaluacio\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(cf_matrix)\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy: \", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Ajustar el model usant una cerca exhaustiva (_Grid Search_)\n",
    "\n",
    "Els paràmetres del nostre model que podem ajustar manualment, es a dir que no són apresos de les dades d'entrenament, s'anomenen hiper-paràmetres. Ajustar el seu valor de manera intuïtiva o mitjançant successions de proves i errors pot ser una tasca llarga, per no dir impossible en el cas de models amb molts paràmetres com poden ser els _Random Forests_.\n",
    "\n",
    "Existeix una tècnica de cerca exhaustiva dels valors òptims dels hiper-paràmetres coneguda amb el nom de _Grid Search_ que ens permet automatitzar aquesta cerca penalitzant el cost temporal del procés d'entrenament.\n",
    "\n",
    "\n",
    "## Combinació de _K-Fold_ amb _Grid Search_\n",
    "\n",
    "La combinació de les dues tècniques explicades anteriorment és una de les més emprades, és coneix amb el nom de\n",
    "_nested cross-validation_. En aquest cas tenim dos bucles, un dins l'altra: el més extern en el que es divideix el conjunt\n",
    "d'entrenament usant _K-folding_ i un altre d'intern en el qual es realitza la cerca dels millors hiper-paràmetres.\n",
    "\n",
    "L'esquema que segueix és el següent:\n",
    "\n",
    "<img src=\"imatges/grid_search_k_fold.png\" width=\"600\"/>\n",
    "\n",
    "## Resum del procés complet\n",
    "\n",
    "En aquesta pràctica aplicarem l'explicat fins ara usant les eines que _Scikit_ posa al nostre abast. Les passes a seguir són:\n",
    "\n",
    "0. Creació del conjunt de dades.\n",
    "1. Separació del conjunt de dades: entrenament i test.\n",
    "2. Definició dels paràmetres a ajustar segons el model triat. El format de la graella de paràmetres és un diccionari on la clau és el nom del paràmetre i el valor una llista amb tots els valors a provar. [Diccionaris a Python](https://docs.python.org/3/tutorial/datastructures.html#dictionaries).\n",
    "3. Aplicam la cerca exhaustiva (_grid search_) juntament amb _k-folding_. Usarem la funció _GridSearchCV_ [enllaç](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV): `GridSearchCV(estimator, param_grid, cv=None, verbose=0)`.\n",
    "4. Entrenam amb el millor model obtingut i el conjunt d'entrenament sencer. Podem obtenir el millor model resultant de la passa anterior amb l'atribut `best_estimator_` de l'objecte `GridSearchCV`. _Nota:_ Si mirau la documentació observareu que podem obtenir altres informacions del procés de la cerca exhaustiva.\n",
    "5. Obtenir els resultats finals amb el conjunt de _test_."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
